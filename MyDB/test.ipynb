{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['legacy_store_details', 'legacy_users', 'orders_table']\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "import data_cleaning as dc\n",
    "import data_extraction as de\n",
    "from database_utils import DatabaseConnector\n",
    "from data_extraction import DataExtractor\n",
    "from data_cleaning import DataCleaning\n",
    "import pandas as pd\n",
    "\n",
    "dab = DatabaseConnector('db_creds.yaml')\n",
    "dab.init_db_engine()\n",
    "#List the tables\n",
    "tables = dab.list_db_tables()\n",
    "#prints tables\n",
    "print(tables)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>company</th>\n",
       "      <th>email_address</th>\n",
       "      <th>address</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>join_date</th>\n",
       "      <th>user_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sigfried</td>\n",
       "      <td>Noack</td>\n",
       "      <td>1990-09-30</td>\n",
       "      <td>Heydrich Junitz KG</td>\n",
       "      <td>rudi79@winkler.de</td>\n",
       "      <td>Zimmerstr. 1/0\\n59015 Gießen</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>+49(0) 047905356</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Guy</td>\n",
       "      <td>Allen</td>\n",
       "      <td>1940-12-01</td>\n",
       "      <td>Fox Ltd</td>\n",
       "      <td>rhodesclifford@henderson.com</td>\n",
       "      <td>Studio 22a\\nLynne terrace\\nMcCarthymouth\\nTF0 9GH</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>(0161) 496 0674</td>\n",
       "      <td>2001-12-20</td>\n",
       "      <td>8fe96c3a-d62d-4eb5-b313-cf12d9126a49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>1995-08-02</td>\n",
       "      <td>Johnson, Jones and Harris</td>\n",
       "      <td>glen98@bryant-marshall.co.uk</td>\n",
       "      <td>92 Ann drive\\nJoanborough\\nSK0 6LR</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>+44(0)121 4960340</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>fc461df4-b919-48b2-909e-55c95a03fe6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Darren</td>\n",
       "      <td>Hussain</td>\n",
       "      <td>1972-09-23</td>\n",
       "      <td>Wheeler LLC</td>\n",
       "      <td>daniellebryan@thompson.org</td>\n",
       "      <td>19 Robinson meadow\\nNew Tracy\\nW22 2QG</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>(0306) 999 0871</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>6104719f-ef14-4b09-bf04-fb0c4620acb0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Garry</td>\n",
       "      <td>Stone</td>\n",
       "      <td>1952-12-20</td>\n",
       "      <td>Warner Inc</td>\n",
       "      <td>billy14@long-warren.com</td>\n",
       "      <td>3 White pass\\nHunterborough\\nNN96 4UE</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>0121 496 0225</td>\n",
       "      <td>2006-09-01</td>\n",
       "      <td>9523a6d3-b2dd-4670-a51a-36aebc89f579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index first_name last_name date_of_birth                    company  \\\n",
       "0      0   Sigfried     Noack    1990-09-30         Heydrich Junitz KG   \n",
       "1      1        Guy     Allen    1940-12-01                    Fox Ltd   \n",
       "2      2      Harry  Lawrence    1995-08-02  Johnson, Jones and Harris   \n",
       "3      3     Darren   Hussain    1972-09-23                Wheeler LLC   \n",
       "4      4      Garry     Stone    1952-12-20                 Warner Inc   \n",
       "\n",
       "                  email_address  \\\n",
       "0             rudi79@winkler.de   \n",
       "1  rhodesclifford@henderson.com   \n",
       "2  glen98@bryant-marshall.co.uk   \n",
       "3    daniellebryan@thompson.org   \n",
       "4       billy14@long-warren.com   \n",
       "\n",
       "                                             address         country  \\\n",
       "0                       Zimmerstr. 1/0\\n59015 Gießen         Germany   \n",
       "1  Studio 22a\\nLynne terrace\\nMcCarthymouth\\nTF0 9GH  United Kingdom   \n",
       "2                 92 Ann drive\\nJoanborough\\nSK0 6LR  United Kingdom   \n",
       "3             19 Robinson meadow\\nNew Tracy\\nW22 2QG  United Kingdom   \n",
       "4              3 White pass\\nHunterborough\\nNN96 4UE  United Kingdom   \n",
       "\n",
       "  country_code       phone_number   join_date  \\\n",
       "0           DE   +49(0) 047905356  2018-10-10   \n",
       "1           GB    (0161) 496 0674  2001-12-20   \n",
       "2           GB  +44(0)121 4960340  2016-12-16   \n",
       "3           GB    (0306) 999 0871  2004-02-23   \n",
       "4           GB      0121 496 0225  2006-09-01   \n",
       "\n",
       "                              user_uuid  \n",
       "0  93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8  \n",
       "1  8fe96c3a-d62d-4eb5-b313-cf12d9126a49  \n",
       "2  fc461df4-b919-48b2-909e-55c95a03fe6b  \n",
       "3  6104719f-ef14-4b09-bf04-fb0c4620acb0  \n",
       "4  9523a6d3-b2dd-4670-a51a-36aebc89f579  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de = DataExtractor()\n",
    "original_df = de.extract_user_data()\n",
    "\n",
    "#Copy the data from the table into a Pandas DF\n",
    "#pandaDF = dab.read_db_creds()\n",
    "#for col in pandaDF.columns:\n",
    "    #print(col)\n",
    "\n",
    "#db_yaml_file='db_creds.yaml'\n",
    "#db_connector=DatabaseConnector(db_yaml_file)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "legacy_users = de.read_rds_table('legacy_users')\n",
    "legacy_users.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15320 entries, 0 to 15319\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          15320 non-null  int64 \n",
      " 1   first_name     15320 non-null  object\n",
      " 2   last_name      15320 non-null  object\n",
      " 3   date_of_birth  15320 non-null  object\n",
      " 4   company        15320 non-null  object\n",
      " 5   email_address  15320 non-null  object\n",
      " 6   address        15320 non-null  object\n",
      " 7   country        15320 non-null  object\n",
      " 8   country_code   15320 non-null  object\n",
      " 9   phone_number   15320 non-null  object\n",
      " 10  join_date      15320 non-null  object\n",
      " 11  user_uuid      15320 non-null  object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "legacy_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United Kingdom    9371\n",
       "Germany           4708\n",
       "United States     1205\n",
       "NULL                21\n",
       "GMRBOMI0O1           1\n",
       "7ZNO5EBALT           1\n",
       "3518UD5CE8           1\n",
       "RQRB7RMTAD           1\n",
       "PNRMPSYR1J           1\n",
       "5EFAFD0JLI           1\n",
       "YOTSVPRBQ7           1\n",
       "50KUU3PQUF           1\n",
       "EWE3U0DZIV           1\n",
       "XN9NGL5C0B           1\n",
       "S0E37H52ON           1\n",
       "XGI7FM0VBJ           1\n",
       "AJ1ENKS3QL           1\n",
       "I7G4DMDZOZ           1\n",
       "T4WBZSW0XI           1\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legacy_users['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United Kingdom    9371\n",
       "Germany           4708\n",
       "United States     1205\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are many that are not actually a country. There are only three correct values. \n",
    "\n",
    "a = ['United Kingdom','United States','Germany']\n",
    "cleaned_users = legacy_users[legacy_users.country.isin(a)]\n",
    "cleaned_users['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GB     9365\n",
       "DE     4708\n",
       "US     1205\n",
       "GGB       6\n",
       "Name: country_code, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_users['country_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurir\\AppData\\Local\\Temp\\ipykernel_28012\\1802846815.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_users['country_code'].replace(to_replace='GGB',value='GB', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GB    9371\n",
       "DE    4708\n",
       "US    1205\n",
       "Name: country_code, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_users['country_code'].replace(to_replace='GGB',value='GB', inplace=True)\n",
    "cleaned_users['country_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1990-09-30\n",
      "1        1940-12-01\n",
      "2        1995-08-02\n",
      "3        1972-09-23\n",
      "4        1952-12-20\n",
      "            ...    \n",
      "15315    1943-08-09\n",
      "15316    1948-08-20\n",
      "15317    1940-10-09\n",
      "15318    1952-06-04\n",
      "15319    1994-03-27\n",
      "Name: date_of_birth, Length: 15284, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dobs = print(cleaned_users['date_of_birth'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958-02-02    6\n",
      "1978-01-31    5\n",
      "1956-07-16    5\n",
      "1961-03-27    5\n",
      "1951-01-09    5\n",
      "             ..\n",
      "1938-12-22    1\n",
      "2005-03-28    1\n",
      "1963-04-26    1\n",
      "1964-07-13    1\n",
      "1994-03-27    1\n",
      "Name: date_of_birth, Length: 11344, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Very large data set with, lets see if value count will work? \n",
    "\n",
    "dobs = print(cleaned_users['date_of_birth'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    15268\n",
       "15        6\n",
       "16        5\n",
       "12        4\n",
       "11        1\n",
       "Name: date_of_birth, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need another way to represent data\n",
    "#will count what how many values have varring sets of dob\n",
    "\n",
    "dobs=cleaned_users['date_of_birth']\n",
    "dobs.map(lambda calc: len(calc)).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurir\\AppData\\Local\\Temp\\ipykernel_28012\\1233488452.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  cleaned_users = cleaned_users[dobs.apply(lambda x: len(x)==10)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10    15268\n",
       "Name: date_of_birth, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_users = cleaned_users[dobs.apply(lambda x: len(x)==10)]\n",
    "dobs=cleaned_users['date_of_birth']\n",
    "dobs.map(lambda calc: len(calc)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0047905356\n",
      "1        1614960674\n",
      "2        1214960340\n",
      "3        3069990871\n",
      "4        1214960225\n",
      "            ...    \n",
      "15315    0292018946\n",
      "15316    1144960977\n",
      "15317    0298408192\n",
      "15318    2397113836\n",
      "15319    1314960870\n",
      "Name: phone_number, Length: 15268, dtype: object\n"
     ]
    }
   ],
   "source": [
    "phone_series = cleaned_users['phone_number']\n",
    "phone_series2 = phone_series.apply(lambda x: ''.join([i for i in x if str.isnumeric(i)])[-10:])\n",
    "cleaned_users['phone_number']=phone_series2\n",
    "print(phone_series2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataframes or page in pdf:\n",
      "307\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30060773296197</td>\n",
       "      <td>09/26</td>\n",
       "      <td>Diners Club / Carte Blanche</td>\n",
       "      <td>2015-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349624180933183</td>\n",
       "      <td>10/23</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2001-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>06/23</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2000-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213142929492281</td>\n",
       "      <td>09/27</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502067329974</td>\n",
       "      <td>10/25</td>\n",
       "      <td>Maestro</td>\n",
       "      <td>1997-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15304</th>\n",
       "      <td>180036921556789</td>\n",
       "      <td>12/28</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>1997-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>180018030448512</td>\n",
       "      <td>11/24</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2004-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>3569953313547220</td>\n",
       "      <td>04/24</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2020-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>4444521712606810</td>\n",
       "      <td>06/27</td>\n",
       "      <td>VISA 16 digit</td>\n",
       "      <td>2008-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>372031786522735</td>\n",
       "      <td>02/30</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2009-02-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            card_number expiry_date                card_provider  \\\n",
       "0        30060773296197       09/26  Diners Club / Carte Blanche   \n",
       "1       349624180933183       10/23             American Express   \n",
       "2      3529023891650490       06/23                 JCB 16 digit   \n",
       "3       213142929492281       09/27                 JCB 15 digit   \n",
       "4          502067329974       10/25                      Maestro   \n",
       "...                 ...         ...                          ...   \n",
       "15304   180036921556789       12/28                 JCB 15 digit   \n",
       "15305   180018030448512       11/24                 JCB 15 digit   \n",
       "15306  3569953313547220       04/24                 JCB 16 digit   \n",
       "15307  4444521712606810       06/27                VISA 16 digit   \n",
       "15308   372031786522735       02/30             American Express   \n",
       "\n",
       "      date_payment_confirmed  \n",
       "0                 2015-11-25  \n",
       "1                 2001-06-18  \n",
       "2                 2000-12-26  \n",
       "3                 2011-02-12  \n",
       "4                 1997-03-13  \n",
       "...                      ...  \n",
       "15304             1997-06-06  \n",
       "15305             2004-06-16  \n",
       "15306             2020-02-05  \n",
       "15307             2008-06-16  \n",
       "15308             2009-02-04  \n",
       "\n",
       "[15309 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    " \n",
    "def retrieve_pdf_data(url: str):\n",
    "    '''takes PDF url as input and outputs PDF data as table'''\n",
    "    dfs =tabula.read_pdf(url,pages='all')\n",
    "    card_data=pd.concat(dfs,ignore_index=True)\n",
    "    print('number of dataframes or page in pdf:')\n",
    "    print(len(dfs))\n",
    "    return card_data\n",
    "\n",
    "retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataframes or page in pdf:\n",
      "307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VISA 16 digit                  2426\n",
       "JCB 16 digit                   2403\n",
       "VISA 13 digit                  1382\n",
       "JCB 15 digit                   1363\n",
       "VISA 19 digit                  1349\n",
       "Diners Club / Carte Blanche    1312\n",
       "American Express               1297\n",
       "Maestro                        1281\n",
       "Discover                       1260\n",
       "Mastercard                     1211\n",
       "NULL                             11\n",
       "OGJTXI6X1H                        1\n",
       "BU9U947ZGV                        1\n",
       "UA07L7EILH                        1\n",
       "XGZBYBYGUW                        1\n",
       "DLWF2HANZF                        1\n",
       "1M38DYQTZV                        1\n",
       "WJVMUO4QX6                        1\n",
       "DE488ORDXY                        1\n",
       "5CJH7ABGDR                        1\n",
       "JCQMU8FN85                        1\n",
       "TS8A81WFXV                        1\n",
       "JRPRLPIBZ2                        1\n",
       "NB71VBAHJE                        1\n",
       "5MFWFBZRM9                        1\n",
       "Name: card_provider, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    " \n",
    "def retrieve_pdf_data(url: str):\n",
    "    '''takes PDF url as input and outputs PDF data as table'''\n",
    "    dfs =tabula.read_pdf(url,pages='all')\n",
    "    card_data=pd.concat(dfs,ignore_index=True)\n",
    "    print('number of dataframes or page in pdf:')\n",
    "    print(len(dfs))\n",
    "    return card_data['card_provider'].value_counts()\n",
    "\n",
    "retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataframes or page in pdf:\n",
      "307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VISA 16 digit                  2426\n",
       "JCB 16 digit                   2403\n",
       "VISA 13 digit                  1382\n",
       "JCB 15 digit                   1363\n",
       "VISA 19 digit                  1349\n",
       "Diners Club / Carte Blanche    1312\n",
       "American Express               1297\n",
       "Maestro                        1281\n",
       "Discover                       1260\n",
       "Mastercard                     1211\n",
       "Name: card_provider, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We have 11 Null values and the rest are made up.'''\n",
    "\n",
    "import tabula\n",
    "import pandas as pd\n",
    " \n",
    "def retrieve_pdf_data(url: str):\n",
    "    '''takes PDF url as input and outputs PDF data as table'''\n",
    "    dfs =tabula.read_pdf(url,pages='all')\n",
    "    card_data=pd.concat(dfs,ignore_index=True)\n",
    "    print('number of dataframes or page in pdf:')\n",
    "    print(len(dfs))\n",
    "    '''Card cleaning'''\n",
    "    b = ['VISA 16 digit','JCB 16 digit','VISA 13 digit','JCB 15 digit', 'VISA 19 digit', 'Diners Club / Carte Blanche', 'American Express', 'Maestro', 'Discover', 'Mastercard']\n",
    "    card_data = card_data[card_data.card_provider.isin(b)]\n",
    "    return card_data['card_provider'].value_counts()\n",
    "\n",
    "retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataframes or page in pdf:\n",
      "307\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30060773296197</td>\n",
       "      <td>09/26</td>\n",
       "      <td>Diners Club / Carte Blanche</td>\n",
       "      <td>2015-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349624180933183</td>\n",
       "      <td>10/23</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2001-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>06/23</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2000-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213142929492281</td>\n",
       "      <td>09/27</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502067329974</td>\n",
       "      <td>10/25</td>\n",
       "      <td>Maestro</td>\n",
       "      <td>1997-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15304</th>\n",
       "      <td>180036921556789</td>\n",
       "      <td>12/28</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>1997-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>180018030448512</td>\n",
       "      <td>11/24</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2004-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>3569953313547220</td>\n",
       "      <td>04/24</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2020-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>4444521712606810</td>\n",
       "      <td>06/27</td>\n",
       "      <td>VISA 16 digit</td>\n",
       "      <td>2008-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>372031786522735</td>\n",
       "      <td>02/30</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2009-02-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            card_number expiry_date                card_provider  \\\n",
       "0        30060773296197       09/26  Diners Club / Carte Blanche   \n",
       "1       349624180933183       10/23             American Express   \n",
       "2      3529023891650490       06/23                 JCB 16 digit   \n",
       "3       213142929492281       09/27                 JCB 15 digit   \n",
       "4          502067329974       10/25                      Maestro   \n",
       "...                 ...         ...                          ...   \n",
       "15304   180036921556789       12/28                 JCB 15 digit   \n",
       "15305   180018030448512       11/24                 JCB 15 digit   \n",
       "15306  3569953313547220       04/24                 JCB 16 digit   \n",
       "15307  4444521712606810       06/27                VISA 16 digit   \n",
       "15308   372031786522735       02/30             American Express   \n",
       "\n",
       "      date_payment_confirmed  \n",
       "0                 2015-11-25  \n",
       "1                 2001-06-18  \n",
       "2                 2000-12-26  \n",
       "3                 2011-02-12  \n",
       "4                 1997-03-13  \n",
       "...                      ...  \n",
       "15304             1997-06-06  \n",
       "15305             2004-06-16  \n",
       "15306             2020-02-05  \n",
       "15307             2008-06-16  \n",
       "15308             2009-02-04  \n",
       "\n",
       "[12909 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    " \n",
    "def retrieve_pdf_data(url: str):\n",
    "    '''takes PDF url as input and outputs PDF data as table'''\n",
    "    dfs =tabula.read_pdf(url,pages='all')\n",
    "    card_data=pd.concat(dfs,ignore_index=True)\n",
    "    print('number of dataframes or page in pdf:')\n",
    "    print(len(dfs))\n",
    "    '''Card Provider cleaning'''\n",
    "    b = ['VISA 16 digit','JCB 16 digit','VISA 13 digit','JCB 15 digit', 'VISA 19 digit', 'Diners Club / Carte Blanche', 'American Express', 'Maestro', 'Discover', 'Mastercard']\n",
    "    card_data = card_data[card_data.card_provider.isin(b)]\n",
    "    '''Card number cleaning'''\n",
    "    null_map = card_data.applymap(lambda x: isinstance(x, (int, float)))['card_number']\n",
    "    return card_data.iloc[null_map.values]\n",
    "\n",
    "retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataframes or page in pdf:\n",
      "307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "03/28         163\n",
       "12/29         163\n",
       "01/28         162\n",
       "12/26         152\n",
       "05/25         152\n",
       "             ... \n",
       "VNLNMWPJII      1\n",
       "WDWMN9TU45      1\n",
       "ACT9K6ECRJ      1\n",
       "8YJ3TYH6Z5      1\n",
       "2ANT8LW3I5      1\n",
       "Name: expiry_date, Length: 136, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''From 15309 rows × 4 columns to 12909 rows × 4 columns '''\n",
    "import tabula\n",
    "import pandas as pd\n",
    " \n",
    "def retrieve_pdf_data(url: str):\n",
    "    '''takes PDF url as input and outputs PDF data as table'''\n",
    "    dfs =tabula.read_pdf(url,pages='all')\n",
    "    card_data=pd.concat(dfs,ignore_index=True)\n",
    "    print('number of dataframes or page in pdf:')\n",
    "    print(len(dfs))\n",
    "    return card_data['expiry_date'].value_counts()\n",
    "\n",
    "retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataframes or page in pdf:\n",
      "307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2032-10-01    148\n",
       "2032-01-01    135\n",
       "2032-06-01    127\n",
       "2032-09-01    125\n",
       "2032-05-01    125\n",
       "2032-08-01    124\n",
       "2032-07-01    118\n",
       "2032-03-01    117\n",
       "2032-04-01    112\n",
       "2032-02-01    103\n",
       "2032-11-01     78\n",
       "Name: expiry_date, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    " \n",
    "def retrieve_pdf_data(url: str):\n",
    "    '''takes PDF url as input and outputs PDF data as table'''\n",
    "    dfs =tabula.read_pdf(url,pages='all')\n",
    "    card_data=pd.concat(dfs,ignore_index=True)\n",
    "    print('number of dataframes or page in pdf:')\n",
    "    print(len(dfs))\n",
    "    '''Clean date data'''\n",
    "    card_data['expiry_date'] = pd.to_datetime(card_data['expiry_date'], errors='coerce')\n",
    "    card_data = card_data.loc[card_data['expiry_date'].notnull()]\n",
    "    return card_data['expiry_date'].value_counts()\n",
    "\n",
    "retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataframes or page in pdf:\n",
      "307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "03/28    163\n",
       "12/29    163\n",
       "01/28    162\n",
       "05/25    152\n",
       "12/26    152\n",
       "        ... \n",
       "02/32    103\n",
       "02/23     94\n",
       "09/25     92\n",
       "11/32     78\n",
       "11/22     37\n",
       "Name: expiry_date, Length: 121, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    " \n",
    "def retrieve_pdf_data(url: str):\n",
    "    '''takes PDF url as input and outputs PDF data as table'''\n",
    "    dfs =tabula.read_pdf(url,pages='all')\n",
    "    card_data=pd.concat(dfs,ignore_index=True)\n",
    "    print('number of dataframes or page in pdf:')\n",
    "    print(len(dfs))\n",
    "    '''Clean date data'''\n",
    "    card_data['expiry_date'] = pd.to_datetime(card_data['expiry_date'], format='%m/%y', errors='coerce')\n",
    "    # Filter out rows where 'expiry_date' is not a valid date\n",
    "    card_data = card_data.loc[card_data['expiry_date'].notnull()]\n",
    "    # Convert 'expiry_date' column back to the 'MM/YY' format\n",
    "    card_data['expiry_date'] = card_data['expiry_date'].dt.strftime('%m/%y')\n",
    "    # Return the value counts of the remaining valid dates\n",
    "    return card_data['expiry_date'].value_counts()\n",
    "\n",
    "retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataframes or page in pdf:\n",
      "307\n",
      "Number of rows after before Card Provider cleaning: 15309\n",
      "Number of rows after Card Provider cleaning: 15284\n",
      "Number of rows after expiry_date cleaning: 15284\n",
      "Number of rows after card number cleaning: 12909\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30060773296197</td>\n",
       "      <td>09/26</td>\n",
       "      <td>Diners Club / Carte Blanche</td>\n",
       "      <td>2015-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349624180933183</td>\n",
       "      <td>10/23</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2001-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>06/23</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2000-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213142929492281</td>\n",
       "      <td>09/27</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502067329974</td>\n",
       "      <td>10/25</td>\n",
       "      <td>Maestro</td>\n",
       "      <td>1997-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15304</th>\n",
       "      <td>180036921556789</td>\n",
       "      <td>12/28</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>1997-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>180018030448512</td>\n",
       "      <td>11/24</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2004-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>3569953313547220</td>\n",
       "      <td>04/24</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2020-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>4444521712606810</td>\n",
       "      <td>06/27</td>\n",
       "      <td>VISA 16 digit</td>\n",
       "      <td>2008-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>372031786522735</td>\n",
       "      <td>02/30</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2009-02-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            card_number expiry_date                card_provider  \\\n",
       "0        30060773296197       09/26  Diners Club / Carte Blanche   \n",
       "1       349624180933183       10/23             American Express   \n",
       "2      3529023891650490       06/23                 JCB 16 digit   \n",
       "3       213142929492281       09/27                 JCB 15 digit   \n",
       "4          502067329974       10/25                      Maestro   \n",
       "...                 ...         ...                          ...   \n",
       "15304   180036921556789       12/28                 JCB 15 digit   \n",
       "15305   180018030448512       11/24                 JCB 15 digit   \n",
       "15306  3569953313547220       04/24                 JCB 16 digit   \n",
       "15307  4444521712606810       06/27                VISA 16 digit   \n",
       "15308   372031786522735       02/30             American Express   \n",
       "\n",
       "      date_payment_confirmed  \n",
       "0                 2015-11-25  \n",
       "1                 2001-06-18  \n",
       "2                 2000-12-26  \n",
       "3                 2011-02-12  \n",
       "4                 1997-03-13  \n",
       "...                      ...  \n",
       "15304             1997-06-06  \n",
       "15305             2004-06-16  \n",
       "15306             2020-02-05  \n",
       "15307             2008-06-16  \n",
       "15308             2009-02-04  \n",
       "\n",
       "[12909 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    " \n",
    "def retrieve_pdf_data(url: str):\n",
    "    '''takes PDF url as input and outputs PDF data as table'''\n",
    "    dfs =tabula.read_pdf(url,pages='all')\n",
    "    card_data=pd.concat(dfs,ignore_index=True)\n",
    "    print('number of dataframes or page in pdf:')\n",
    "    print(len(dfs))\n",
    "    print('Number of rows after before Card Provider cleaning:', len(card_data))\n",
    "    '''Card Provider cleaning'''\n",
    "    b = ['VISA 16 digit','JCB 16 digit','VISA 13 digit','JCB 15 digit', 'VISA 19 digit', 'Diners Club / Carte Blanche', 'American Express', 'Maestro', 'Discover', 'Mastercard']\n",
    "    card_data = card_data[card_data.card_provider.isin(b)]\n",
    "    print('Number of rows after Card Provider cleaning:', len(card_data))\n",
    "\n",
    "    '''Clean expiry_date col'''#May not need as makes no difference. \n",
    "    card_data['expiry_date'] = pd.to_datetime(card_data['expiry_date'], format='%m/%y', errors='coerce')\n",
    "    # Filter out rows where 'expiry_date' is not a valid date\n",
    "    card_data = card_data.loc[card_data['expiry_date'].notnull()]\n",
    "    # Convert 'expiry_date' column back to the 'MM/YY' format\n",
    "    card_data['expiry_date'] = card_data['expiry_date'].dt.strftime('%m/%y')\n",
    "    print('Number of rows after expiry_date cleaning:', len(card_data))\n",
    "\n",
    "    '''Card number cleaning'''\n",
    "    null_map = card_data.applymap(lambda x: isinstance(x, (int, float)))['card_number']\n",
    "    card_data_cleaned = card_data.iloc[null_map.values]\n",
    "    print('Number of rows after card number cleaning:', len(card_data_cleaned))\n",
    "    return card_data_cleaned\n",
    "\n",
    "retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'statusCode': 200, 'number_stores': 451}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def list_number_of_stores1():\n",
    "        headers = {\n",
    "            \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "        return response\n",
    "\n",
    "def list_number_of_stores2():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    print(response.json())  # Print the JSON response for debugging\n",
    "    return response     \n",
    "\n",
    "\n",
    "list_number_of_stores2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected record 0\n",
      "Collected record 10\n",
      "Collected record 20\n",
      "Collected record 30\n",
      "Collected record 40\n",
      "Collected record 50\n",
      "Collected record 60\n",
      "Collected record 70\n",
      "Collected record 80\n",
      "Collected record 90\n",
      "Collected record 100\n",
      "Collected record 110\n",
      "Collected record 120\n",
      "Collected record 130\n",
      "Collected record 140\n",
      "Collected record 150\n",
      "Collected record 160\n",
      "Collected record 170\n",
      "Collected record 180\n",
      "Collected record 190\n",
      "Collected record 200\n",
      "Collected record 210\n",
      "Collected record 220\n",
      "Collected record 230\n",
      "Collected record 240\n",
      "Collected record 250\n",
      "Collected record 260\n",
      "Collected record 270\n",
      "Collected record 280\n",
      "Collected record 290\n",
      "Collected record 300\n",
      "Collected record 310\n",
      "Collected record 320\n",
      "Collected record 330\n",
      "Collected record 340\n",
      "Collected record 350\n",
      "Collected record 360\n",
      "Collected record 370\n",
      "Collected record 380\n",
      "Collected record 390\n",
      "Collected record 400\n",
      "Collected record 410\n",
      "Collected record 420\n",
      "Collected record 430\n",
      "Collected record 440\n",
      "Collected record 450\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>WEB-1388012W</td>\n",
       "      <td>325</td>\n",
       "      <td>2010-06-12</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>None</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-9B97EE4E</td>\n",
       "      <td>34</td>\n",
       "      <td>1996-10-25</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Heckerstraße 4/5\\n50491 Säckingen, Landshut</td>\n",
       "      <td>48.52961</td>\n",
       "      <td>None</td>\n",
       "      <td>Landshut</td>\n",
       "      <td>LA-0772C7B9</td>\n",
       "      <td>92</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>12.16179</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury</td>\n",
       "      <td>51.26</td>\n",
       "      <td>None</td>\n",
       "      <td>Westbury</td>\n",
       "      <td>WE-1DE82CEE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-2.1875</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...</td>\n",
       "      <td>53.0233</td>\n",
       "      <td>None</td>\n",
       "      <td>Belper</td>\n",
       "      <td>BE-18074576</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Local</td>\n",
       "      <td>-1.48119</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>446</td>\n",
       "      <td>Täschestraße 25\\n39039 Nördlingen, Kirchlengern</td>\n",
       "      <td>52.2</td>\n",
       "      <td>None</td>\n",
       "      <td>Kirchlengern</td>\n",
       "      <td>KI-78096E8C</td>\n",
       "      <td>61</td>\n",
       "      <td>2005-05-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>8.63333</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>447</td>\n",
       "      <td>K0ODETRLS3</td>\n",
       "      <td>K8CXLZDP07</td>\n",
       "      <td>UXMWDMX1LC</td>\n",
       "      <td>3VHFDNP8ET</td>\n",
       "      <td>9D4LK7X4LZ</td>\n",
       "      <td>D23PCWSM6S</td>\n",
       "      <td>36IIMAQD58</td>\n",
       "      <td>NN04B3F6UQ</td>\n",
       "      <td>JZP8MIJTPZ</td>\n",
       "      <td>B3EH2ZGQAV</td>\n",
       "      <td>1WZB1TE1HL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>448</td>\n",
       "      <td>Studio 8\\nMoss mall\\nWest Linda\\nM0E 6XR, High...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>None</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-EEA7AE62</td>\n",
       "      <td>33</td>\n",
       "      <td>1998-05-14</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>449</td>\n",
       "      <td>Baumplatz 6\\n80114 Kötzting, Bretten</td>\n",
       "      <td>49.03685</td>\n",
       "      <td>None</td>\n",
       "      <td>Bretten</td>\n",
       "      <td>BR-662EC74C</td>\n",
       "      <td>35</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>Local</td>\n",
       "      <td>8.70745</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>Gotthilf-Rose-Straße 7/3\\n45457 Feuchtwangen, ...</td>\n",
       "      <td>50.64336</td>\n",
       "      <td>None</td>\n",
       "      <td>Bad Honnef</td>\n",
       "      <td>BA-B4AED588</td>\n",
       "      <td>36</td>\n",
       "      <td>2001-05-12</td>\n",
       "      <td>Local</td>\n",
       "      <td>7.2278</td>\n",
       "      <td>DE</td>\n",
       "      <td>eeEurope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                            address   longitude  \\\n",
       "0        0                                                N/A         N/A   \n",
       "1        1  Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...    51.62907   \n",
       "2        2        Heckerstraße 4/5\\n50491 Säckingen, Landshut    48.52961   \n",
       "3        3  5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury       51.26   \n",
       "4        4  Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...     53.0233   \n",
       "..     ...                                                ...         ...   \n",
       "446    446    Täschestraße 25\\n39039 Nördlingen, Kirchlengern        52.2   \n",
       "447    447                                         K0ODETRLS3  K8CXLZDP07   \n",
       "448    448  Studio 8\\nMoss mall\\nWest Linda\\nM0E 6XR, High...    51.62907   \n",
       "449    449               Baumplatz 6\\n80114 Kötzting, Bretten    49.03685   \n",
       "450    450  Gotthilf-Rose-Straße 7/3\\n45457 Feuchtwangen, ...    50.64336   \n",
       "\n",
       "            lat      locality    store_code staff_numbers opening_date  \\\n",
       "0           N/A           N/A  WEB-1388012W           325   2010-06-12   \n",
       "1          None  High Wycombe   HI-9B97EE4E            34   1996-10-25   \n",
       "2          None      Landshut   LA-0772C7B9            92   2013-04-12   \n",
       "3          None      Westbury   WE-1DE82CEE            69   2014-01-02   \n",
       "4          None        Belper   BE-18074576            35   2019-09-09   \n",
       "..          ...           ...           ...           ...          ...   \n",
       "446        None  Kirchlengern   KI-78096E8C            61   2005-05-12   \n",
       "447  UXMWDMX1LC    3VHFDNP8ET    9D4LK7X4LZ    D23PCWSM6S   36IIMAQD58   \n",
       "448        None  High Wycombe   HI-EEA7AE62            33   1998-05-14   \n",
       "449        None       Bretten   BR-662EC74C            35   2020-10-17   \n",
       "450        None    Bad Honnef   BA-B4AED588            36   2001-05-12   \n",
       "\n",
       "      store_type    latitude country_code   continent  \n",
       "0     Web Portal        None         None        None  \n",
       "1          Local    -0.74934           GB      Europe  \n",
       "2    Super Store    12.16179           DE      Europe  \n",
       "3    Super Store     -2.1875           GB      Europe  \n",
       "4          Local    -1.48119           GB      Europe  \n",
       "..           ...         ...          ...         ...  \n",
       "446  Super Store     8.63333           DE      Europe  \n",
       "447   NN04B3F6UQ  JZP8MIJTPZ   B3EH2ZGQAV  1WZB1TE1HL  \n",
       "448        Local    -0.74934           GB      Europe  \n",
       "449        Local     8.70745           DE      Europe  \n",
       "450        Local      7.2278           DE    eeEurope  \n",
       "\n",
       "[451 rows x 12 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Collected record {i}\")\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    return df        \n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected record 0\n",
      "Collected record 10\n",
      "Collected record 20\n",
      "Collected record 30\n",
      "Collected record 40\n",
      "Collected record 50\n",
      "Collected record 60\n",
      "Collected record 70\n",
      "Collected record 80\n",
      "Collected record 90\n",
      "Collected record 100\n",
      "Collected record 110\n",
      "Collected record 120\n",
      "Collected record 130\n",
      "Collected record 140\n",
      "Collected record 150\n",
      "Collected record 160\n",
      "Collected record 170\n",
      "Collected record 180\n",
      "Collected record 190\n",
      "Collected record 200\n",
      "Collected record 210\n",
      "Collected record 220\n",
      "Collected record 230\n",
      "Collected record 240\n",
      "Collected record 250\n",
      "Collected record 260\n",
      "Collected record 270\n",
      "Collected record 280\n",
      "Collected record 290\n",
      "Collected record 300\n",
      "Collected record 310\n",
      "Collected record 320\n",
      "Collected record 330\n",
      "Collected record 340\n",
      "Collected record 350\n",
      "Collected record 360\n",
      "Collected record 370\n",
      "Collected record 380\n",
      "Collected record 390\n",
      "Collected record 400\n",
      "Collected record 410\n",
      "Collected record 420\n",
      "Collected record 430\n",
      "Collected record 440\n",
      "Collected record 450\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 451 entries, 0 to 450\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          451 non-null    int64 \n",
      " 1   address        451 non-null    object\n",
      " 2   longitude      451 non-null    object\n",
      " 3   lat            11 non-null     object\n",
      " 4   locality       451 non-null    object\n",
      " 5   store_code     451 non-null    object\n",
      " 6   staff_numbers  451 non-null    object\n",
      " 7   opening_date   451 non-null    object\n",
      " 8   store_type     451 non-null    object\n",
      " 9   latitude       450 non-null    object\n",
      " 10  country_code   450 non-null    object\n",
      " 11  continent      450 non-null    object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 42.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Collected record {i}\")\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    return df        \n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key).info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20            18\n",
       "33            17\n",
       "28            16\n",
       "29            16\n",
       "7             16\n",
       "              ..\n",
       "76             1\n",
       "58             1\n",
       "56             1\n",
       "2429OB3LMM     1\n",
       "D23PCWSM6S     1\n",
       "Name: staff_numbers, Length: 114, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    return df\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['staff_numbers'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0     18\n",
       "33.0     17\n",
       "29.0     16\n",
       "28.0     16\n",
       "7.0      16\n",
       "         ..\n",
       "71.0      1\n",
       "128.0     1\n",
       "76.0      1\n",
       "58.0      1\n",
       "61.0      1\n",
       "Name: staff_numbers, Length: 101, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    '''Clean Staff numbers'''\n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df['staff_numbers'] = pd.to_numeric(df['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df.dropna(subset=['staff_numbers'])\n",
    "    return df_cleaned\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['staff_numbers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0     18\n",
      "33.0     17\n",
      "29.0     16\n",
      "28.0     16\n",
      "7.0      16\n",
      "         ..\n",
      "71.0      1\n",
      "128.0     1\n",
      "76.0      1\n",
      "58.0      1\n",
      "61.0      1\n",
      "Name: staff_numbers, Length: 101, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "\n",
    "    \n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    \n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df['staff_numbers'] = pd.to_numeric(df['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df.dropna(subset=['staff_numbers'])\n",
    "    return df_cleaned['staff_numbers'].value_counts()\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key = {'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "staff_counts = retrieve_store_data(num_stores, get_stores_endpoint, API_key)\n",
    "print(staff_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurir\\AppData\\Local\\Temp\\ipykernel_24448\\3007001750.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned.loc[:, 'staff_numbers'] = df_cleaned['staff_numbers'].astype(int).copy()\n",
      "C:\\Users\\yurir\\AppData\\Local\\Temp\\ipykernel_24448\\3007001750.py:26: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_cleaned.loc[:, 'staff_numbers'] = df_cleaned['staff_numbers'].astype(int).copy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20     18\n",
       "33     17\n",
       "29     16\n",
       "28     16\n",
       "7      16\n",
       "       ..\n",
       "71      1\n",
       "128     1\n",
       "76      1\n",
       "58      1\n",
       "61      1\n",
       "Name: staff_numbers, Length: 101, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    '''Clean Staff numbers'''\n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df['staff_numbers'] = pd.to_numeric(df['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df.dropna(subset=['staff_numbers'])\n",
    "    #The .loc accessor ensures that the changes made to the subset of the DataFrame will be propagated back to the original DataFrame.\n",
    "    df_cleaned.loc[:, 'staff_numbers'] = df_cleaned['staff_numbers'].astype(int).copy()\n",
    "    return df_cleaned\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['staff_numbers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20     18\n",
       "33     17\n",
       "29     16\n",
       "28     16\n",
       "7      16\n",
       "       ..\n",
       "71      1\n",
       "128     1\n",
       "76      1\n",
       "58      1\n",
       "61      1\n",
       "Name: staff_numbers, Length: 101, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    '''Clean Staff numbers'''\n",
    "    # Copy the DataFrame to avoid SettingWithCopyWarning\n",
    "    df_cleaned = df.copy()\n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df_cleaned['staff_numbers'] = pd.to_numeric(df_cleaned['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df_cleaned.dropna(subset=['staff_numbers'])\n",
    "    df_cleaned['staff_numbers'] = df_cleaned['staff_numbers'].astype(int)\n",
    "    return df_cleaned\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['staff_numbers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GB            265\n",
       "DE            141\n",
       "US             34\n",
       "NULL            3\n",
       "YELVM536YT      1\n",
       "FP8DLXQVGH      1\n",
       "HMHIFNLOBN      1\n",
       "F3AO8V2LHU      1\n",
       "OH20I92LX3      1\n",
       "OYVW925ZL8      1\n",
       "B3EH2ZGQAV      1\n",
       "Name: country_code, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Does previous code also get rid?'''\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    return df\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['country_code'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GB    263\n",
       "DE    139\n",
       "US     33\n",
       "Name: country_code, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    '''Clean Staff numbers'''\n",
    "    # Copy the DataFrame to avoid SettingWithCopyWarning\n",
    "    df_cleaned = df.copy()\n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df_cleaned['staff_numbers'] = pd.to_numeric(df_cleaned['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df_cleaned.dropna(subset=['staff_numbers'])\n",
    "    df_cleaned['staff_numbers'] = df_cleaned['staff_numbers'].astype(int)\n",
    "    return df_cleaned\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['country_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Europe     402\n",
       "America     33\n",
       "Name: continent, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    '''Clean Staff numbers'''\n",
    "    # Copy the DataFrame to avoid SettingWithCopyWarning\n",
    "    df_cleaned = df.copy()\n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df_cleaned['staff_numbers'] = pd.to_numeric(df_cleaned['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df_cleaned.dropna(subset=['staff_numbers'])\n",
    "    df_cleaned['staff_numbers'] = df_cleaned['staff_numbers'].astype(int)\n",
    "    df_cleaned['continent'] = df_cleaned['continent'].replace('eeEurope', 'Europe').replace('eeAmerica', 'America')\n",
    "    return df_cleaned\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['continent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N/A    1\n",
       "Name: lat, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    '''Clean Staff numbers'''\n",
    "    # Copy the DataFrame to avoid SettingWithCopyWarning\n",
    "    df_cleaned = df.copy()\n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df_cleaned['staff_numbers'] = pd.to_numeric(df_cleaned['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df_cleaned.dropna(subset=['staff_numbers'])\n",
    "    df_cleaned['staff_numbers'] = df_cleaned['staff_numbers'].astype(int)\n",
    "    df_cleaned['continent'] = df_cleaned['continent'].replace('eeEurope', 'Europe').replace('eeAmerica', 'America')\n",
    "    return df_cleaned\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['lat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>WEB-1388012W</td>\n",
       "      <td>325</td>\n",
       "      <td>2010-06-12</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-9B97EE4E</td>\n",
       "      <td>34</td>\n",
       "      <td>1996-10-25</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Heckerstraße 4/5\\n50491 Säckingen, Landshut</td>\n",
       "      <td>48.52961</td>\n",
       "      <td>Landshut</td>\n",
       "      <td>LA-0772C7B9</td>\n",
       "      <td>92</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>12.16179</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury</td>\n",
       "      <td>51.26</td>\n",
       "      <td>Westbury</td>\n",
       "      <td>WE-1DE82CEE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-2.1875</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...</td>\n",
       "      <td>53.0233</td>\n",
       "      <td>Belper</td>\n",
       "      <td>BE-18074576</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Local</td>\n",
       "      <td>-1.48119</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            address longitude  \\\n",
       "0      0                                                N/A       N/A   \n",
       "1      1  Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...  51.62907   \n",
       "2      2        Heckerstraße 4/5\\n50491 Säckingen, Landshut  48.52961   \n",
       "3      3  5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury     51.26   \n",
       "4      4  Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...   53.0233   \n",
       "\n",
       "       locality    store_code  staff_numbers opening_date   store_type  \\\n",
       "0           N/A  WEB-1388012W            325   2010-06-12   Web Portal   \n",
       "1  High Wycombe   HI-9B97EE4E             34   1996-10-25        Local   \n",
       "2      Landshut   LA-0772C7B9             92   2013-04-12  Super Store   \n",
       "3      Westbury   WE-1DE82CEE             69   2014-01-02  Super Store   \n",
       "4        Belper   BE-18074576             35   2019-09-09        Local   \n",
       "\n",
       "   latitude country_code continent  \n",
       "0      None         None      None  \n",
       "1  -0.74934           GB    Europe  \n",
       "2  12.16179           DE    Europe  \n",
       "3   -2.1875           GB    Europe  \n",
       "4  -1.48119           GB    Europe  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Need to remove the column lat which only have nul values'''\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    '''Clean Staff numbers'''\n",
    "    # Copy the DataFrame to avoid SettingWithCopyWarning\n",
    "    df_cleaned = df.copy()\n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df_cleaned = df.drop('lat', axis=1)\n",
    "    df_cleaned['staff_numbers'] = pd.to_numeric(df_cleaned['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df_cleaned.dropna(subset=['staff_numbers'])\n",
    "    df_cleaned['staff_numbers'] = df_cleaned['staff_numbers'].astype(int)\n",
    "    df_cleaned['continent'] = df_cleaned['continent'].replace('eeEurope', 'Europe').replace('eeAmerica', 'America')\n",
    "    return df_cleaned\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004-01-23     3\n",
       "2014-05-21     2\n",
       "1998-12-19     2\n",
       "1998-09-29     2\n",
       "2006-10-03     2\n",
       "              ..\n",
       "May 2003 27    1\n",
       "1997-02-07     1\n",
       "2003-04-07     1\n",
       "2006-10-18     1\n",
       "2001-05-12     1\n",
       "Name: opening_date, Length: 427, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    '''Clean Staff numbers'''\n",
    "    # Copy the DataFrame to avoid SettingWithCopyWarning\n",
    "    df_cleaned = df.copy()\n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df_cleaned = df.drop('lat', axis=1)\n",
    "    df_cleaned['staff_numbers'] = pd.to_numeric(df_cleaned['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df_cleaned.dropna(subset=['staff_numbers'])\n",
    "    df_cleaned['staff_numbers'] = df_cleaned['staff_numbers'].astype(int)\n",
    "    df_cleaned['continent'] = df_cleaned['continent'].replace('eeEurope', 'Europe').replace('eeAmerica', 'America')\n",
    "    return df_cleaned\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['opening_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chapletown          14\n",
       "Belper              13\n",
       "Bushey              12\n",
       "Exeter              11\n",
       "Arbroath            10\n",
       "                    ..\n",
       "Redding              1\n",
       "Wittenau             1\n",
       "Fairview Heights     1\n",
       "Brierley Hill        1\n",
       "Westchester          1\n",
       "Name: locality, Length: 116, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Need to keep the unorganised dates can sort out another time in SQL'''\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def list_number_of_stores():\n",
    "    headers = {\n",
    "        \"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"\n",
    "    }\n",
    "    response = requests.get(\"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\", headers=headers)\n",
    "    return response.json()[\"number_stores\"]\n",
    "\n",
    "def retrieve_store_data(number_stores, retrieve_store_endpoint, header):\n",
    "    stores_data = []\n",
    "    for i in range(number_stores):\n",
    "        store_url = retrieve_store_endpoint+str(i)\n",
    "        try:\n",
    "            response = requests.get(store_url, headers=header)\n",
    "        except:\n",
    "            print(\"there was an error!\")    \n",
    "        stores_data.append(response.json())\n",
    "    df = pd.DataFrame(stores_data)\n",
    "    '''Clean Staff numbers'''\n",
    "    # Copy the DataFrame to avoid SettingWithCopyWarning\n",
    "    df_cleaned = df.copy()\n",
    "    # Convert staff_numbers column to numeric and drop non-numeric values\n",
    "    df_cleaned = df.drop('lat', axis=1)\n",
    "    df_cleaned['staff_numbers'] = pd.to_numeric(df_cleaned['staff_numbers'], errors='coerce')\n",
    "    df_cleaned = df_cleaned.dropna(subset=['staff_numbers'])\n",
    "    df_cleaned['staff_numbers'] = df_cleaned['staff_numbers'].astype(int)\n",
    "    df_cleaned['continent'] = df_cleaned['continent'].replace('eeEurope', 'Europe').replace('eeAmerica', 'America')\n",
    "    return df_cleaned\n",
    "\n",
    "num_stores = list_number_of_stores()\n",
    "API_key={'x-api-key':'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "get_stores_endpoint='https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "retrieve_store_data(num_stores, get_stores_endpoint, API_key)['locality'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b088b0735cf1bb78b1692d859b66fe172702674ac068ffd05b959ef5f9b63c35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
